{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d9734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla \n",
    "import math \n",
    "import random \n",
    "import time \n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import random \n",
    "from yaml.loader import SafeLoader\n",
    "import onnx\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8211097",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed3f4f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input name images\n",
      "input shape [1, 3, 640, 640]\n",
      "input type tensor(float)\n",
      "output name output\n",
      "output shape ['Concatoutput_dim_0', 7]\n",
      "output type tensor(float)\n"
     ]
    }
   ],
   "source": [
    "# change the second line to the path of your weights \n",
    "# this is what starts the onnx runtime \n",
    "session = ort.InferenceSession(\n",
    "        'yolo7.onnx',\n",
    "        providers=['CUDAExecutionProvider', 'CPUExecutionProvider'])\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "input_shape = session.get_inputs()[0].shape\n",
    "input_type = session.get_inputs()[0].type\n",
    "output_name = session.get_outputs()[0].name\n",
    "output_shape = session.get_outputs()[0].shape\n",
    "output_type = session.get_outputs()[0].type\n",
    "# this is just to see what everything looks like, can be removed \n",
    "print(\"input name\", input_name)\n",
    "print(\"input shape\", input_shape)\n",
    "print(\"input type\", input_type)\n",
    "print(\"output name\", output_name)\n",
    "print(\"output shape\", output_shape)\n",
    "print(\"output type\", output_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fde10718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as the previous code block but a different shorter way to achieve it\n",
    "outname = [i.name for i in session.get_outputs()]\n",
    "inname = [i.name for i in session.get_inputs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26937188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Classes are as follows: ['bike', 'motobike', 'person', 'traffic_light_green', 'traffic_light_orange', 'traffic_light_red', 'traffic_sign_30', 'traffic_sign_60', 'traffic_sign_90', 'vehicle']\n"
     ]
    }
   ],
   "source": [
    "# Connect the client and set up bp library and spawn points\n",
    "# standard carla set up \n",
    "client = carla.Client('localhost', 2000) \n",
    "world = client.get_world()\n",
    "bp_lib = world.get_blueprint_library() \n",
    "spawn_points = world.get_map().get_spawn_points() \n",
    "settings = world.get_settings()\n",
    "settings.fixed_delta_seconds = 0.01\n",
    "world.apply_settings(settings)\n",
    "# path to your yaml file\n",
    "with open('data.yaml', mode='r') as f:\n",
    "    data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "\n",
    "CLASSES = data_yaml['names']\n",
    "print('The Classes are as follows:',CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1b4412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera width is  640  and camera height is  640\n"
     ]
    }
   ],
   "source": [
    "# Spawn ego vehicle, rgb camera and pedestrians \n",
    "vehicle_bp = bp_lib.find('vehicle.audi.a2') \n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "# Move spectator behind vehicle to view\n",
    "spectator = world.get_spectator() \n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=1,z=2)),vehicle.get_transform().rotation) \n",
    "spectator.set_transform(transform)\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb') \n",
    "camera_bp.set_attribute('image_size_x', '640')\n",
    "camera_bp.set_attribute('image_size_y', '640')\n",
    "# this location is important, if you set it too close\n",
    "# the object detection starts predicting the ego vehicle as\n",
    "# a car, which is not what i want\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(x=1,z=2)) #Change this to move camera\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "# time.sleep cuz carla is a bit slow slow \n",
    "# allows carla to catch up with the camera being initialized\n",
    "time.sleep(0.2)\n",
    "spectator.set_transform(camera.get_transform())\n",
    "# Get camera dimensions and initialise dictionary                       \n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "print('Camera width is ',image_w,' and camera height is ',image_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af02eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spawn 50 vehicles \n",
    "\n",
    "for i in range(50): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) \n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aee547fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback stores sensor data in a dictionary for use outside callback    \n",
    "# also used for object detection          \n",
    "def camera_callback(image, data_dict):\n",
    "    \n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    # ONNX expects things in a particular format\n",
    "    # so the CARLA camera data needs to be reshaped accordingly\n",
    "    # first remove the alpha channel\n",
    "\n",
    "    \n",
    "    frame = cv2.cvtColor(data_dict['image'], cv2.COLOR_RGBA2RGB)\n",
    "    # then transpose it \n",
    "    transposed_image = frame.transpose((2,0,1))\n",
    "    # expand the dimensions, sounds cool but its not \n",
    "\n",
    "    expanded_dimensions = np.expand_dims(transposed_image,0)\n",
    "    # change to float because it does not like int \n",
    "    inputImage = expanded_dimensions.astype(np.float32)\n",
    "    # normalize because everyone likes nice numbers\n",
    "    inputImage /= 255\n",
    "    # start infering with ONNX\n",
    "    outputs = session.run(outname, {input_name: inputImage})[0]\n",
    "    # this is the source image needed for opencv to display the preds\n",
    "    image = data_dict['image']\n",
    "    # you can use this if you want, i dont like the color randomizer\n",
    "    # it basically randomizes the bounding box color that will come on the\n",
    "    # predictions\n",
    "    colorRandomizer = np.random.uniform(0, 255, size=(len(CLASSES), 3))\n",
    "\n",
    "    # YOLOv7 comes with built in NMS so this is all that is needed to display\n",
    "    # the predictions\n",
    "    # super convenient!\n",
    "\n",
    "    for i,(batch_id,x0,y0,x1,y1,cls_id,score) in enumerate(outputs):\n",
    "        \n",
    "        box = np.array([x0,y0,x1,y1])\n",
    "        box = box.round().astype(np.int32).tolist()\n",
    "        class_id = int(cls_id)\n",
    "        floatscore = round(float(score),3)\n",
    "        name = CLASSES[class_id]\n",
    "        objectScore = int(floatscore*100)\n",
    "        color = colorRandomizer[class_id]\n",
    "        # you can print this text to see everything in the console as well\n",
    "        text = f'{name}: {objectScore}%'\n",
    "        # change the color to (0,0,0) or some other rgb value\n",
    "        # if you dont want the randomizer\n",
    "        cv2.rectangle(image, box[:2],box[2:] , color ,2 ) \n",
    "        cv2.putText(image,text,(box[0], box[1] - 2),cv2.FONT_HERSHEY_SIMPLEX,0.5,[0, 0, 0],thickness=2) \n",
    "        # slows down the simulation in order to show the predictions, otherwise it goes fast fast \n",
    "\n",
    "        time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75d24d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# use this after you have closed the opencv predictions window\n",
    "# CARLA has some crazy memory leaks \n",
    "camera.destroy()\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3be9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what you use to start the object detection \n",
    "\n",
    "camera.listen(lambda image: camera_callback(image, camera_data))\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Game loop\n",
    "while True:\n",
    "    \n",
    "\n",
    "    # Imshow renders sensor data to display\n",
    "    cv2.imshow('YOLOv7 Detections', camera_data['image'])\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close OpenCV window when finished\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# tadaaa, everything works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
