{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b6dec-c0f6-4496-9b75-d74bcba07183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla \n",
    "import math \n",
    "import random \n",
    "import time \n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b82a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the path of your weights \n",
    "net = cv2.dnn.readNetFromONNX('yolov5weights.onnx')\n",
    "print(net)\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e786f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect the client and set up bp library and spawn points\n",
    "# standard carla set up \n",
    "client = carla.Client('localhost', 2000) \n",
    "world = client.get_world()\n",
    "bp_lib = world.get_blueprint_library() \n",
    "spawn_points = world.get_map().get_spawn_points() \n",
    "settings = world.get_settings()\n",
    "settings.fixed_delta_seconds = 0.01\n",
    "world.apply_settings(settings)\n",
    "# path to your yaml file\n",
    "with open('data.yaml', mode='r') as f:\n",
    "    data_yaml = yaml.load(f,Loader=SafeLoader)\n",
    "\n",
    "CLASSES = data_yaml['names']\n",
    "\n",
    "# thresholds, change according to your use case \n",
    "# or dont! \n",
    "\n",
    "conf_threshold = 0.5\n",
    "class_threshold = 0.4\n",
    "# variable declarations \n",
    "IM_WIDTH = 640\n",
    "IM_HEIGHT = 640\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c7c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spawn ego vehicle, rgb camera and pedestrians \n",
    "\n",
    "vehicle_bp = bp_lib.find('vehicle.audi.a2') \n",
    "vehicle = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points))\n",
    "# Move spectator behind vehicle to view\n",
    "spectator = world.get_spectator() \n",
    "transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=1,z=2)),vehicle.get_transform().rotation) \n",
    "spectator.set_transform(transform)\n",
    "camera_bp = bp_lib.find('sensor.camera.rgb') \n",
    "camera_bp.set_attribute('image_size_x', '640')\n",
    "camera_bp.set_attribute('image_size_y', '640')\n",
    "\n",
    "camera_init_trans = carla.Transform(carla.Location(x=1,z=2)) #Change this to move camera\n",
    "camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=vehicle)\n",
    "# time.sleep cuz carla is a bit slow slow \n",
    "# allows carla to catch up with the camera being initialized\n",
    "\n",
    "time.sleep(0.2)\n",
    "spectator.set_transform(camera.get_transform())\n",
    "# Get camera dimensions and initialise dictionary                       \n",
    "image_w = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "image_h = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "\n",
    "camera_data = {'image': np.zeros((image_h, image_w, 4))}\n",
    "print('Camera width is ',image_w,' and camera height is ',image_h)\n",
    "\n",
    "time.sleep(0.2)\n",
    "# spawn 50 vehicles \n",
    "\n",
    "for i in range(50): \n",
    "    vehicle_bp = random.choice(bp_lib.filter('vehicle')) \n",
    "    npc = world.try_spawn_actor(vehicle_bp, random.choice(spawn_points)) \n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.set_autopilot(True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2272b40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback stores sensor data in a dictionary for use outside callback    \n",
    "# also used for object detection                      \n",
    "def camera_callback(image, data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data), (image.height, image.width, 4))\n",
    "    frame = cv2.cvtColor(data_dict['image'], cv2.COLOR_RGBA2RGB)\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1/255, (640, 640), (0, 0, 0), True, crop = False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    # forward pass\n",
    "    preds = net.forward()\n",
    "    # create empty arrays for storing\n",
    "    detections = preds[0] \n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classes = []\n",
    "    \n",
    "    imageW = camera_bp.get_attribute(\"image_size_x\").as_int()\n",
    "    imageH = camera_bp.get_attribute(\"image_size_y\").as_int()\n",
    "    # factor isnt that important if your carla camera is already 640*640\n",
    "    x_factor = imageW/640\n",
    "    y_factor = imageH/640\n",
    "\n",
    "    # this for loop extracts all the predictions based conf and class thresh\n",
    "    for i in range(len(detections)):\n",
    "        row = detections[i]\n",
    "        confidence = row[4] \n",
    "        if confidence > conf_threshold:\n",
    "            # getting the best score and then get its index position, id stands for index\n",
    "            class_score = row[5:].max() \n",
    "            class_id = row[5:].argmax()\n",
    "\n",
    "            if class_score>class_threshold:\n",
    "                cx,cy,w,h = row[0:4]\n",
    "                # coordinates need to be scaled \n",
    "                left = int((cx-0.5*w)*x_factor)\n",
    "                top = int((cy-0.5*h)*y_factor)\n",
    "                width = int(w*x_factor)\n",
    "                height = int(h*y_factor)\n",
    "                box = np.array([left,top,width,height])\n",
    "                # append everything so you can access it later for nms \n",
    "                confidences.append(confidence)\n",
    "                boxes.append(box)\n",
    "                classes.append(class_id)\n",
    "\n",
    "    # now convert it to the format nms wants, honestly this step could be skipped\n",
    "    boxes_array = np.array(boxes)\n",
    "    boxes_np = boxes_array.tolist()\n",
    "    confidences_array = np.array(confidences)\n",
    "    confidences_np = confidences_array.tolist()\n",
    "    # .flatten() can be removed but your milleage may vary\n",
    "    # it was quite finnicky in my testing\n",
    "    index = cv2.dnn.NMSBoxes(boxes_np,confidences_np,0.25,0.45).flatten()\n",
    "    \n",
    "    # need the source image to tell opencv what to display it on\n",
    "    # i4 is the source image coming from the camera sensor\n",
    "    i4 = data_dict['image']\n",
    "    # extract the predictions post NMS\n",
    "    # now you are ready to display everything\n",
    "    for ind in index:\n",
    "        x,y,w,h = boxes_np[ind]\n",
    "        bb_conf = int(confidences_np[ind]*100)\n",
    "        classes_id = classes[ind]\n",
    "        class_name = CLASSES[classes_id]\n",
    "\n",
    "        text = f'{class_name}: {bb_conf}%'\n",
    "        # print is just to show it in the console, you can remove this if you dont want anything verbose\n",
    "        print(text)\n",
    "\n",
    "        cv2.rectangle(i4,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "        \n",
    "        cv2.putText(i4,text,(x,y-5),cv2.FONT_HERSHEY_PLAIN,0.7,(0,0,0),1)\n",
    "        \n",
    "        # slows down the simulation in order to show the predictions, otherwise it goes fast fast \n",
    "        time.sleep(0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this after you have closed the opencv predictions window\n",
    "# CARLA has some crazy memory leaks \n",
    "camera.destroy()\n",
    "for v in world.get_actors().filter('*vehicle*'): \n",
    "    v.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc3fb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is what you use to start the object detection \n",
    "\n",
    "camera.listen(lambda image: camera_callback(image, camera_data))\n",
    "cv2.waitKey(1)\n",
    "\n",
    "# Game loop\n",
    "while True:\n",
    "    \n",
    "\n",
    "    # Imshow renders sensor data to display\n",
    "    cv2.imshow('YOLOv5 Detections', camera_data['image'])\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# Close OpenCV window when finished\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# tadaaa, everything works!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
